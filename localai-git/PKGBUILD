_pkgbase="localai"
pkgbase="${_pkgbase}-git"
pkgname=(${pkgbase} ${pkgbase}-rocm ${pkgbase}-rocm-python ${pkgbase}-python)
pkgver=2.26.0.35.gba66aa33
pkgrel=1
pkgdesc="Self-hosted OpenAI API alternative - Open Source, community-driven and local-first."
url="https://github.com/mudler/LocalAI"
options=('!ccache' '!lto')
license=('MIT')
arch=('x86_64')
provides=('localai' "local-ai=${pkgver}")
conflicts=('localai' 'local-ai')
backup=("etc/${_pkgbase}/${_pkgbase}.conf")
source=("${_pkgbase}"::"git+https://github.com/mudler/LocalAI" "README.md" "${_pkgbase}.conf"
	"${_pkgbase}.service" "${_pkgbase}.tmpfiles" "${_pkgbase}.sysusers")
sha256sums=('SKIP' 'SKIP' 'SKIP' 'SKIP' 'SKIP' 'SKIP')
depends=('protobuf' 'grpc' 'espeak-ng')
makedepends=('go' 'git' 'cmake' 'opencv' 'openmpi' 'blas-openblas' 'sdl2' 'ffmpeg' 'upx' 'protoc-gen-go'
	'protoc-gen-go-grpc' 'python-protobuf' 'python-grpcio' 'python-grpcio-tools' 'onnxruntime'
	'rocm-hip-sdk' 'miopen-hip' 'rccl' 'magma-hip')

_python_depends=('python-protobuf' 'python-grpcio' 'python-certifi' 'python-pillow'
	'python-opencv' 'python-numpy' 'python-pytorch' 'python-torchaudio' 'python-torchvision'
	'python-transformers' 'python-sentencepiece' 'python-peft' 'python-accelerate')

_python_backends=("bark bark" "coqui coqui-tts" "diffusers diffusers compel optimum-quanto"
 "parler-tts llvmlite" "rerankers rerankers[transformers]" "sentencetransformers sentence-transformers"
 "transformers" "transformers-musicgen" "vall-e-x")

_ENABLE_CPU=${_ENABLE_CPU:1}
_ENABLE_CUDA=${_ENABLE_CUDA:0}
_ENABLE_ROCM=${_ENABLE_ROCM:1}
_ENABLE_PARALLEL=${_ENABLE_PARALLEL:1}
_ENABLE_PIPER=${_ENABLE_PIPER:1}
_ENABLE_WHISPER=${_ENABLE_WHISPER:1}
_ENABLE_PYTHON=${_ENABLE_PYTHON:1}
_IS_PYTHON_FLAVOR=0
_AMDGPU_TARGETS="gfx803"
_OPTIONAL_GRPC="${_OPTIONAL_GRPC:-}"
_OPTIONAL_MAKE_ARGS="${_OPTIONAL_MAKE_ARGS:-}"
_EXTERNAL_SOURCES="$_EXTERNAL_SOURCES sources/whisper.cpp"
_OPTIONAL_GRPC="backend-assets/grpc/whisper $_OPTIONAL_GRPC"
_EXTERNAL_SOURCES="$_EXTERNAL_SOURCES sources/go-piper"
_OPTIONAL_GRPC="backend-assets/grpc/piper $_OPTIONAL_GRPC"
_GO_TAGS="tts"
_GRPC_BACKENDS="backend-assets/grpc/local-store \
$_OPTIONAL_GRPC"

if [[ $_ENABLE_CPU = 1 ]]; then
  pkgname+=("${pkgbase}")
  if [[ $_ENABLE_PYTHON = 1 ]]; then
    pkgname+=("${pkgbase}-python")
  fi
fi

if [[ $_ENABLE_ROCM = 1 ]]; then
  pkgname+=("${pkgbase}-rocm")
  if [[ $_ENABLE_PYTHON = 1 ]]; then
    pkgname+=("${pkgbase}-rocm-python")
  fi
fi


pkgver() {
  cd "${srcdir}/${_pkgbase}"
  (git describe --always --tags | tr "-" "." | tail -c +2)
}

prepare() {
  cd "${srcdir}/${_pkgbase}"
  cat - << EOF

prepare():

Build Options:

_ENABLE_CPU=$_ENABLE_CPU
_ENABLE_CUDA=$_ENABLE_CUDA
_ENABLE_ROCM=$_ENABLE_ROCM
_ENABLE_PYTHON=$_ENABLE_PYTHON
_ENABLE_PARALLEL=$_ENABLE_PARALLEL
_ENABLE_PIPER=$_ENABLE_PIPER
_ENABLE_WHISPER=$_ENABLE_WHISPER
_OPTIONAL_MAKE_ARGS=$_OPTIONAL_MAKE_ARGS
_EXTERNAL_SOURCES=$_EXTERNAL_SOURCES
_DISABLED_MOD_EDIT=$_DISABLED_MOD_EDIT
_OPTIONAL_GRPC=$_OPTIONAL_GRPC
_GRPC_BACKENDS=$_GRPC_BACKENDS


EOF

  sed -ri "s#get-sources: .*#get-sources: $_EXTERNAL_SOURCES#g" Makefile
  for i in $_DISABLED_MOD_EDIT; do
    sed -ri 's#.+\-replace github.com/'$i'.+##g' Makefile
  done
  mkdir -p "sources"
  make $_OPTIONAL_MAKE_ARGS $_EXTERNAL_SOURCES
  mkdir -p "sources/go-piper/piper-phonemize/pi/lib"
  touch "sources/go-piper/piper-phonemize/pi/lib/keep"
  sed -ri 's#(\$\(MAKE\) -C sources/go-piper libpiper_binding.a) example/main#\1#g' Makefile

  cd "${srcdir}"
  for n in "${_pkgbase}-cpu" "${_pkgbase}-rocm"; do
    if test -d "$n"; then rm -rf "$n"; fi
    cp -r "${_pkgbase}" "$n"
  done

  cd "${srcdir}/${_pkgbase}-rocm"
   for i in \
     backend/cpp/llama/llama.cpp/Makefile \
     sources/whisper.cpp/Makefile; do
       mkdir -p $(dirname $i); touch $i; 
       sed -ri 's/^(.+HIPFLAGS.+\+=).+offload-arch=.+$/\1 -DGPU_TARGETS="$(GPU_TARGETS)"/g' "$i"
   done
}

_build() {
  make BUILD_TYPE="$1" protogen-python
  mkdir -p backend-assets/grpc
  cp -a backend/python backend-assets/grpc/python

  if test "$1" = "hipblas"; then
    _LLAMA_CPP_BACKEND="backend-assets/grpc/llama-cpp-hipblas"
  else
    _LLAMA_CPP_BACKEND="backend-assets/grpc/llama-cpp-avx2"
  fi

  cat - << EOF


_build($1):
GO_TAGS=$_GO_TAGS
OPTIONAL_MAKE_ARGS=$_OPTIONAL_MAKE_ARGS
LLAMA_BACKEND=$_LLAMA_CPP_BACKEND
OTHER_GRPC_BACKENDS=$_GRPC_BACKENDS

EOF

  _nproc=1
  if [[ $_ENABLE_PARALLEL = 1 ]]; then
    _nproc=$(nproc)
  fi

  make -j$(nproc) \
    BUILD_TYPE="$1" \
    GRPC_BACKENDS="$_LLAMA_CPP_BACKEND $_GRPC_BACKENDS" \
    GO_TAGS="$_GO_TAGS" $_OPTIONAL_MAKE_ARGS build
}

build() {
    cd "${srcdir}/${_pkgbase}"
    _build


  if [[ $_ENABLE_CPU = 1 ]]; then
    cd "${srcdir}/${_pkgbase}-cpu"
    _build openblas
  fi

  if [[ $_ENABLE_ROCM = 1 ]]; then
    cd "${srcdir}/${_pkgbase}-rocm"
    export ROCM_HOME="${ROCM_HOME:-/opt/rocm}"
    export ROCM_VERSION="$(cat $ROCM_HOME/.info/version)"
    export PATH="$ROC_HOME/bin:$PATH"

    CXXFLAGS="$CXXFLAGS -fcf-protection=none" MAGMA_HOME="$ROCM_HOME" \
      AMDGPU_TARGETS="$_AMDGPU_TARGETS" GPU_TARGETS="$_AMDGPU_TARGETS" \
        _build hipblas
  fi
}

_package_install() {
  cd "${srcdir}/${_pkgbase}"
  install -Dm755 "local-ai" "${pkgdir}/usr/bin/localai"
  ln -s "/usr/bin/localai" "${pkgdir}/usr/bin/local-ai"
  install -Dm644 LICENSE -t "${pkgdir}/usr/share/licenses/${_pkgbase}"
  install -Dm644 README.md -t "${pkgdir}/usr/share/doc/${_pkgbase}"
  install -Dm644 "${srcdir}/README.md" "${pkgdir}/usr/share/doc/${_pkgbase}/README-build.md"
  install -Dm644 ${srcdir}/${_pkgbase}.conf -t "${pkgdir}/etc/${_pkgbase}"
  _python_backends_str=""
  if [[ $_IS_PYTHON_FLAVOR = 1 ]]; then
    _python_backends_str=$(printf "%s\n" "${_python_backends[@]}")
  fi
  echo "ARCH_LOCALAI_PYTHON_BACKENDS=\"${_python_backends_str}\"" \
      > "${pkgdir}/etc/${_pkgbase}/python_backends.conf"
  install -Dm644 ${srcdir}/${_pkgbase}.service -t "${pkgdir}/usr/lib/systemd/system"
  install -Dm644 ${srcdir}/${_pkgbase}.sysusers "${pkgdir}/usr/lib/sysusers.d/${_pkgbase}.conf"
  install -Dm644 ${srcdir}/${_pkgbase}.tmpfiles "${pkgdir}/usr/lib/tmpfiles.d/${_pkgbase}.conf"
}

package_localai-git() {
  cd "${srcdir}/${_pkgbase}-cpu"
  depends+=('openblas')
  if [[ $_ENABLE_PIPER = 1 ]]; then depends+=('onnxruntime'); fi
  if [[ $_IS_PYTHON_FLAVOR = 1 ]]; then depends+=("${_python_depends[@]}"); fi
  _package_install
}

package_localai-git-rocm() {
  cd "${srcdir}/${_pkgbase}-rocm"
  pkgdesc+=' (with ROCM support)'
  depends+=('rocm-hip-runtime' 'hipblas' 'rocblas')
  if [[ $_ENABLE_PIPER = 1 ]]; then depends+=('onnxruntime'); fi
  if [[ $_IS_PYTHON_FLAVOR = 1 ]]; then depends+=("${_python_depends[@]}"); depends+=('python-pytorch-rocm'); fi
  _package_install
}

package_localai-git-python() {
  _IS_PYTHON_FLAVOR=1
  package_localai-git "$@"
}

package_localai-git-rocm-python() {
  _IS_PYTHON_FLAVOR=1
  package_localai-git-rocm "$@"
}
